Architektury Výpočetních Systémů (AVS 2021)
Projekt č. 2 (PMC)
Login: xpolok03

Úloha 1: Paralelizace původního řešení
===============================================================================

1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?

   Je vhodnější pararelizovat vnější smyčku ve funkci marchCubes, ma dostatečný počet iterací (gridSize^3) na to aby byla pararelizace výhodna a výpočet vně jedné iterace je dostatečně dlouhý na to aby nás nebrzdila režie.
   Naopak pokud bychom se rozhodli pararelizovat smyčku ve funkci evaluateFieldAt muselo by master vlákno čekat na výpočet vzdálenosti  vůči všem bodům příslušných vláken, zbortit výsledek a až pak se posunout na další pozici, navíc celý výpočet buildCube by probíhal sekvenčně.
   Další možností se jeví zpararelizovat obě smyčky, avšak nutná režie a přepinání kontextu zpomaluje výpočet.
   Zrychlení výpočtu bylo dále dosaženo vektorizaci smyčky v evaluateFieldAt.

2) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? 
   Jaký vliv má velikost "chunk" při dynamickém plánování (8, 16, 32, 64)?

   Jelikož výpočet mezi iteracemi se nijak neliší je zcela přirozené použít statické plánování. Provedené experimenty toto zjištění potvrdily.
   Iterace na sebe nejsou nijak závislé tedy ideálně chceme rozdistribuovat všechen výpočet mezi vlákna ekvivaletně a vyhnout se jakékoliv režii.
   Uvažme celkový objem práce jako W a počet vláken jako N. Idealní volbou by byl chunk o velikosti W/N.
   V tomto případě se dostaneme s dynamickým plánováním na podobnou rychlost jako ze statickým.



3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?

   Naivním řešením se jeví sekce critical případně atomic, ty však vedou k zbytečnému zámku a čekání mezi vlákny k přístupu k bufferu.
   Předělal jsem tedy 1D buffer na 2D buffer, kde maximální počet vláken úrčuje velikost první dimenze. Příslušné buffery jsou na konci výpočtu zřetězeny.


Úloha 2: Paralelní průchod stromem
===============================================================================

1) Stručně popište použití OpenMP tasků ve vašem řešení.

   Jak je naznačeno tasky jsou vytvořeny po rozgenerování potomků aktuálního bloku.
   Task je vytvořen až po ověření možnosti průchodu hledaného povrchu daným potomkem.

2) Jakým způsobem jste realizovali sesbírání celkového počtu trojúhelníků?

   Podobně jako v předchozím případě jsem řešil sesbirání tvorbou čítačů pro příslušná vlákna, tak aby bylo zamezeno zbytečné nutnosti atomické operace.
   Celkový počet je potom sečten v sekvenční části sečtením čítačů příslušných vláken.

3) Jaký vliv má na vaše řešení tzv. "cut-off"? Je vhodné vytvářet nový 
   task pro každou krychli na nejnižší úrovni?

   Hodnota idealního "cutt off" je přímo závislá na objektu, jež se snažíme vykreslit, počtu dostupných fyzických jader a parametrech mGridSize a mIsoLevel.
   Příliš nízký "cutt off" vede k spuštění výpočtu i pro prostor, ve kterém může být majoritní prostor bloků prázdný.
   Naopak příliš vysoký "cutt off" vede k vytvoření velkého počtu vláken a k tomu spojené přehnané režii.
   Z těchto důvodů jsem se rozhodl zastavit generování potomků v hloubce zanoření 3.

   Určitě není vhodné vytvářet task pro krychli, která neobsahuje hledaný prostor a pro krychle na nejnižší urovní.
   Tasky by obsahovaly pouze jednoduchý výpočet, který by byl doprovozen vysokou režií.

4) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?

   Stejným způsobem jako v bodě 1.3.

Úloha 3: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení (na základě grafů škálování).

   Oba řešení jsou poměrně efektivní.
   Algoritmus loop funguje lépe na menších vstupech. Asymptoticky však dosahují podobných časů.
   U octree čas ušetřeny nepočítaním některých sub-krychlí je ztracen na nutné režii.
   Výkonnost algoritmu octree je dost závislá na zvoleném "cut-off" prahu a rozložení vstupního objektu v prostoru.


2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? (pokud takový případ existuje)

   V grafu silného škálování pro implementaci loop jsou vidět dosti patrné odchylky pro vstup o velikosti 40 na 16 jadrech a vstup o velikosti 320 na 32 jádrech.
   Myslím si, že však tyto výkyvy jsou ovlivěny nezarovnáním dat a přístupovým vzorem do polí hodnot v evaluateFieldAt (původní vector 3D bodů byl převeden na 3 vektory), kdy dochází k výpadkům.

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?

   Jeví se jako efektivnější ačkoliv rozdíl je nepatrný.
   Obdobně se v grafech vyskytují 2 výkyvy - předchozí bod.

Úloha 4: Analýza využití jader pomocí VTune
================================================================================

1) Jaké bylo průměrné využití jader pro všechny tři implementace s omezením na 
   18 vláken? Na kolik procent byly využity?
   
   ref: 0.996, (2.8% vzhledem k 36 logickým, 5.6% vzhledem k 18 logickým)
   loop: 15.450, (42.9% vzhledem k 36 logickým, 85.8% vzhledem k 18 logickým)
   tree: 16.522, (45.9% vzhledem k 36 logickým, 91.8% vzhledem k 18 logickým)

   Nižší využití jader je zapříčiněno vektorizací funkce evaluateFieldAt a sekvenčním předpočítáním některých hodnot z optimalizačních důvodů. (Bez vektorizace se tyto hodnoty pohybovaly nad 90%).

2) Jaké bylo průměrné využití jader pro všechny tři implementace s využitím 
   všech jader? Na kolik procent se podařilo využít obě CPU?
   
   ref: 0.997, 2.8%
   loop: 21.825, 60.6%
   tree: 23.193, 64.4%

   Podobně jako v předchozím případě se zde hodnoty pro loop a tree pohybovaly nad 80% před vektorizací.

3) Jaké jsou závěry z těchto měření?

   Jak už bylo zmíněno implementace loop se zdá efektivnější, což měření potvrzují.
   Je vidět, že implementací jsou poměrně efektivní v obou případech 80%, respektive 90% procent dostupných logických jader je využito.

